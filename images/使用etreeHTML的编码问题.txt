使<div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"/>出现问题</h2><p>今天指导一个学生爬取新浪体育手机版的时候，发现lxml.etree.HTML处理网页源代码会默认修改编码，导致打印出来的内容为乱码。爬取的网址为：<a href="http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10" title="http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10" target="_blank" rel="noopener">http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10</a></p>
<p>首先导入我们需要用到的库文件，然后设置环境：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/><span class="line">6</span><br/></pre></td><td class="code"><pre><span class="line">#-*_coding:utf8-*-</span><br/><span class="line">import requests</span><br/><span class="line">from lxml import etree</span><br/><span class="line">import sys</span><br/><span class="line">reload(sys)</span><br/><span class="line">sys.setdefaultencoding("utf-8")</span><br/></pre></td></tr></table></figure>
<p>然后获取网页的源代码：<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/><span class="line">4</span><br/><span class="line">5</span><br/></pre></td><td class="code"><pre><span class="line"/><br/><span class="line">r = requests.get(url='http://sports.sina.cn/nba/rockets/2015-10-07/detail-ifximrxn8235561.d.html?vt=4&amp;pos=10')# 最基本的GET请求</span><br/><span class="line">r.encoding = 'utf-8'</span><br/><span class="line">r = r.content</span><br/><span class="line">print r</span><br/></pre></td></tr></table></figure></p>
<p>打印出网页源代码，发现中文是乱码，如图：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding1.gif" alt=""/></p>
<p>这是小问题，使用<a href="http://blog.kingname.info/2014/12/14/Python%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%AF%B9%E4%B8%87%E8%83%BD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">Python字符编码的一个相对万能的处理方法</a>这篇文章中讲解的方法，轻松解决。</p>
<p>将：<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">r = r.content</span><br/></pre></td></tr></table></figure></p>
<p>修改为:<br/><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">r = r.content.decode('utf-8').encode('gbk')</span><br/></pre></td></tr></table></figure></p>
<p>可以正常显示中文，如图：<br/><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding2.png" alt=""/></p>
<p>接下来，使用etree.HTML处理源代码，然后使用Xpath提取内容，一切似乎看起来轻车熟路。</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding3.png" alt=""/></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br/><span class="line">2</span><br/><span class="line">3</span><br/></pre></td><td class="code"><pre><span class="line">contentTree = etree.HTML(r)</span><br/><span class="line">title = contentTree.xpath(<span class="string">'//h1[@class="art_title_h1"]/text()'</span>)</span><br/><span class="line"><span class="keyword">print</span> title[<span class="number">0</span>]</span><br/></pre></td></tr></table></figure>
<p>但是当我打印出来，才发现问题没有这么简单。如图：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding4.png" alt=""/></p>
<p>这个时候，我发现使用<a href="http://blog.kingname.info/2014/12/14/Python%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E7%9A%84%E4%B8%80%E4%B8%AA%E7%9B%B8%E5%AF%B9%E4%B8%87%E8%83%BD%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">Python字符编码的一个相对万能的处理方法</a>讲到的办法已经不能解决问题了。</p>
<p>通过调试，我发现抓取到的内容是乱码：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding5.png" alt=""/></p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"/>解决办法</h2><h3 id="使用Scrapy"><a href="#使用Scrapy" class="headerlink" title="使用Scrapy"/>使用Scrapy</h3><p>使用Scrapy的Xpath，正常提取需要的内容：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding6.png" alt=""/></p>
<h3 id="继续用etree"><a href="#继续用etree" class="headerlink" title="继续用etree"/>继续用etree</h3><p>实际上，Scrapy的Xpath底层还是调用的lxml,那为什么它可以，而我直接使用lxml的etree.HTML处理源代码然后Xpath提取内容就出乱码呢？</p>
<p>显然这应该是编码的问题，在使用:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">etree.HTML(r)</span><br/></pre></td></tr></table></figure>
<p>处理源文件的时候，由于没有指定编码，所以它使用了一个默认编码，从而导致和UTF-8冲突，产生乱码。</p>
<p>经过查阅lxml.etree.HTML的文档，我发现etree.HTML有一个参数是parser,这个参数不是必须的，因此省略以后它就会自动使用一个默认的parser。既然如此，那我手动指定一个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">contentTree = etree.HTML(r, parser=etree.HTMLParser(encoding=<span class="string">'utf-8'</span>))</span><br/></pre></td></tr></table></figure>
<p>这里我指定了etree.HTMLParser来作为一个parser,同时，etree.HTMLParser可以接受编码作为参数。于是我指定为UTF-8。</p>
<p>运行看看效果：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding7.png" alt=""/></p>
<p>继续报错，但是出错信息改变了，提示utf8不能解码。请注意第11行，现在源代码是gbk编码，所以使用UTF-8不能解码。于是可以把第11行重新改回原来的样子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br/></pre></td><td class="code"><pre><span class="line">r = r.content</span><br/></pre></td></tr></table></figure>
<p>再一次运行，发现正常抓取信息：</p>
<p><img src="https://kingname-1257411235.cos.ap-chengdu.myqcloud.com/lxmlencoding8.png" alt=""/></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"/>总结</h2><p>这一次的问题提示我们：遇到问题，通过经验解决不了的时候，请回归文档。</p>
<p><em>原文发表在：<a href="http://blog.kingname.info/2015/10/07/lxmlencoding/" target="_blank" rel="noopener">http://blog.kingname.info/2015/10/07/lxmlencoding/</a>转载请注明出处！</em></p>

      
    </div>

    

    
    
    

    
      